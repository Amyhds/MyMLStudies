{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 cost = 0.701546348\n",
      "Epoch: 0002 cost = 0.231422036\n",
      "Epoch: 0003 cost = 0.167427033\n",
      "Epoch: 0004 cost = 0.134825501\n",
      "Epoch: 0005 cost = 0.111704997\n",
      "Epoch: 0006 cost = 0.101142280\n",
      "Epoch: 0007 cost = 0.085034508\n",
      "Epoch: 0008 cost = 0.080768319\n",
      "Epoch: 0009 cost = 0.068649759\n",
      "Epoch: 0010 cost = 0.064436887\n",
      "Epoch: 0011 cost = 0.056208443\n",
      "Epoch: 0012 cost = 0.052251488\n",
      "Epoch: 0013 cost = 0.049863316\n",
      "Epoch: 0014 cost = 0.048229224\n",
      "Epoch: 0015 cost = 0.042993041\n",
      "Epoch: 0016 cost = 0.041112586\n",
      "Epoch: 0017 cost = 0.036705013\n",
      "Epoch: 0018 cost = 0.037128726\n",
      "Epoch: 0019 cost = 0.034930416\n",
      "Epoch: 0020 cost = 0.032686845\n",
      "Learning Finished!\n",
      "Accuracy: 0.9832\n",
      "Label:  [0]\n",
      "Prediction:  [0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sigmoid->relu\n",
    "#Gradient->Adam\n",
    "#random->Xavier\n",
    "#dropout\n",
    "# Lab 7 Learning rate and Evaluation\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from tensorflow.examples.tutorials.mnist \n",
    "import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "tf.reset_default_graph()\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "def xavier_init(n_inputs, n_outputs, uniform=True):\n",
    "  if uniform:\n",
    "    # 6 was used in the paper.\n",
    "    init_range = math.sqrt(6.0 / (n_inputs + n_outputs))\n",
    "    return tf.random_uniform_initializer(-init_range, init_range)\n",
    "  else:\n",
    "    # 3 gives us approximately the same limits as above since this repicks\n",
    "    # values greater than 2 standard deviations from the mean.\n",
    "    stddev = math.sqrt(3.0 / (n_inputs + n_outputs))\n",
    "    return tf.truncated_normal_initializer(stddev=stddev)\n",
    "\n",
    "\n",
    "learning_rate = 0.0007\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "# MNIST data image of shape 28 * 28 = 784\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "# 0 - 9 digits recognition = 10 classes\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "dropout_rate = tf.placeholder(\"float\")\n",
    "\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 512], initializer=xavier_init(784, 512))\n",
    "W2 = tf.get_variable(\"W2\", shape=[512, 400], initializer=xavier_init(512, 400))\n",
    "W3 = tf.get_variable(\"W3\", shape=[400, 256], initializer=xavier_init(400, 256))\n",
    "W4 = tf.get_variable(\"W4\", shape=[256, 256], initializer=xavier_init(256, 256))\n",
    "W5 = tf.get_variable(\"W5\", shape=[256, 10], initializer=xavier_init(256, 10))\n",
    "\n",
    "B1 = tf.Variable(tf.random_normal([512]))\n",
    "B2 = tf.Variable(tf.random_normal([400]))\n",
    "B3 = tf.Variable(tf.random_normal([256]))\n",
    "B4 = tf.Variable(tf.random_normal([256]))\n",
    "B5 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# Construct model\n",
    "_L1 = tf.nn.relu(tf.add(tf.matmul(X,W1),B1))\n",
    "L1 = tf.nn.dropout(_L1, dropout_rate)\n",
    "_L2 = tf.nn.relu(tf.add(tf.matmul(L1, W2),B2)) # Hidden layer with ReLU activation\n",
    "L2 = tf.nn.dropout(_L2, dropout_rate)\n",
    "_L3 = tf.nn.relu(tf.add(tf.matmul(L2, W3),B3)) # Hidden layer with ReLU activation\n",
    "L3 = tf.nn.dropout(_L3, dropout_rate)\n",
    "_L4 = tf.nn.relu(tf.add(tf.matmul(L3, W4),B4)) # Hidden layer with ReLU activation\n",
    "L4 = tf.nn.dropout(_L4, dropout_rate)\n",
    "\n",
    "hypothesis = tf.add(tf.matmul(L4, W5), B5)\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "   logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, dropout_rate: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:',accuracy.eval(session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels, dropout_rate: 1}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1], dropout_rate: 1}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Start learning!\n",
      "Epoch: 0001 cost = 0.445616285\n",
      "Epoch: 0002 cost = 0.159595469\n",
      "Epoch: 0003 cost = 0.118979728\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-39a85f9c62e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mglobal_step\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lab 13 Tensorboard\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.0008\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "TB_SUMMARY_DIR = './tb/mnist'\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# Image input\n",
    "x_image = tf.reshape(X, [-1, 28, 28, 1])\n",
    "tf.summary.image('input', x_image, 3)\n",
    "\n",
    "# dropout (keep_prob) rate  0.7~0.5 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# weights & bias for nn layers\n",
    "# http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "with tf.variable_scope('layer1') as scope:\n",
    "    W1 = tf.get_variable(\"W\", shape=[784, 512],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.Variable(tf.random_normal([512]))\n",
    "    L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "    L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "    tf.summary.histogram(\"X\", X)\n",
    "    tf.summary.histogram(\"weights\", W1)\n",
    "    tf.summary.histogram(\"bias\", b1)\n",
    "    tf.summary.histogram(\"layer\", L1)\n",
    "\n",
    "with tf.variable_scope('layer2') as scope:\n",
    "    W2 = tf.get_variable(\"W\", shape=[512, 512],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b2 = tf.Variable(tf.random_normal([512]))\n",
    "    L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "    L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "    tf.summary.histogram(\"weights\", W2)\n",
    "    tf.summary.histogram(\"bias\", b2)\n",
    "    tf.summary.histogram(\"layer\", L2)\n",
    "\n",
    "with tf.variable_scope('layer3') as scope:\n",
    "    W3 = tf.get_variable(\"W\", shape=[512, 512],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b3 = tf.Variable(tf.random_normal([512]))\n",
    "    L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "    L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "\n",
    "    tf.summary.histogram(\"weights\", W3)\n",
    "    tf.summary.histogram(\"bias\", b3)\n",
    "    tf.summary.histogram(\"layer\", L3)\n",
    "\n",
    "with tf.variable_scope('layer4') as scope:\n",
    "    W4 = tf.get_variable(\"W\", shape=[512, 512],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b4 = tf.Variable(tf.random_normal([512]))\n",
    "    L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "    L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "\n",
    "    tf.summary.histogram(\"weights\", W4)\n",
    "    tf.summary.histogram(\"bias\", b4)\n",
    "    tf.summary.histogram(\"layer\", L4)\n",
    "\n",
    "with tf.variable_scope('layer5') as scope:\n",
    "    W5 = tf.get_variable(\"W\", shape=[512, 10],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b5 = tf.Variable(tf.random_normal([10]))\n",
    "    hypothesis = tf.matmul(L4, W5) + b5\n",
    "\n",
    "    tf.summary.histogram(\"weights\", W5)\n",
    "    tf.summary.histogram(\"bias\", b5)\n",
    "    tf.summary.histogram(\"hypothesis\", hypothesis)\n",
    "\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "tf.summary.scalar(\"loss\", cost)\n",
    "\n",
    "# Summary\n",
    "summary = tf.summary.merge_all()\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Create summary writer\n",
    "writer = tf.summary.FileWriter(TB_SUMMARY_DIR)\n",
    "writer.add_graph(sess.graph)\n",
    "global_step = 0\n",
    "\n",
    "print('Start learning!')\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        s, _ = sess.run([summary, optimizer], feed_dict=feed_dict)\n",
    "        writer.add_summary(s, global_step=global_step)\n",
    "        global_step += 1\n",
    "\n",
    "        avg_cost += sess.run(cost, feed_dict=feed_dict) / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))\n",
    "\n",
    "# plt.imshow(mnist.test.images[r:r + 1].\n",
    "#           reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "# plt.show()\n",
    "\n",
    "'''\n",
    "tensorboard --logdir tb/\n",
    "Starting TensorBoard b'41' on port 6006\n",
    "(You can navigate to http://10.0.1.4:6006)\n",
    "\n",
    "'''\n",
    "'''\n",
    "Epoch: 0001 cost = 0.447322626\n",
    "Epoch: 0002 cost = 0.157285590\n",
    "Epoch: 0003 cost = 0.121884535\n",
    "Epoch: 0004 cost = 0.098128681\n",
    "Epoch: 0005 cost = 0.082901778\n",
    "Epoch: 0006 cost = 0.075337573\n",
    "Epoch: 0007 cost = 0.069752543\n",
    "Epoch: 0008 cost = 0.060884363\n",
    "Epoch: 0009 cost = 0.055276413\n",
    "Epoch: 0010 cost = 0.054631256\n",
    "Epoch: 0011 cost = 0.049675195\n",
    "Epoch: 0012 cost = 0.049125314\n",
    "Epoch: 0013 cost = 0.047231930\n",
    "Epoch: 0014 cost = 0.041290121\n",
    "Epoch: 0015 cost = 0.043621063\n",
    "Learning Finished!\n",
    "Accuracy: 0.9804\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
